# -*- coding: utf-8 -*-
"""Untitled6.ipynb의 사본의 사본

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WK3cGIvfRSjKrn7-niiViYeBzlSz_YIG
"""

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.initializers import Constant
import matplotlib.pyplot as plt

"""# 새 섹션"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

#경고문 삭제
pd.set_option('mode.chained_assignment',  None)

danigoApp = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/APP/다니고밴.csv", encoding = 'utf-8')

danigoIot1 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230309.csv", encoding = 'UTF-8')
danigoIot2 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230310.csv", encoding = 'UTF-8')
danigoIot3 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230311.csv", encoding = 'UTF-8')
danigoIot4 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230312.csv", encoding = 'UTF-8')
danigoIot5 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230313.csv", encoding = 'UTF-8')

danigoIotDatas = []
danigoIotDatas.append(danigoIot1)
danigoIotDatas.append(danigoIot2)
danigoIotDatas.append(danigoIot3)
danigoIotDatas.append(danigoIot4)
danigoIotDatas.append(danigoIot5)

#외부온도 파일
JeonjuTemp1 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/전주 기온 0309.csv", encoding = 'cp949')
JeonjuTemp2 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/전주 기온 0310.csv", encoding = 'cp949')
JeonjuTemp3 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/전주 기온 0311.csv", encoding = 'cp949')
JeonjuTemp4 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/전주 기온 0312.csv", encoding = 'cp949')
JeonjuTemp5 = pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/전주 기온 0313.csv", encoding = 'cp949')

outSideTemps = []
outSideTemps.append(JeonjuTemp1)
outSideTemps.append(JeonjuTemp2)
outSideTemps.append(JeonjuTemp3)
outSideTemps.append(JeonjuTemp4)
outSideTemps.append(JeonjuTemp5)

#외부온도 시간 계산
for i in range(len(outSideTemps)):
    temp_col = []
    n = outSideTemps[i]['일시']
    for j in range(len(outSideTemps[i])):
        sss = str(n[j]).split(' ')
        ttt = sss[1].replace(':', '')
        ddd = int(ttt) * 100
        temp_col.append(ddd)
    outSideTemps[i]['시간'] = temp_col

#시작일 기준 행 추출하기
dataNow = 20230309
tempAvg = []
outTempAvg = []
n = []
m = []
for date in range(5):
    temp = danigoApp[danigoApp['시작일'] == dataNow]

    temp['시작 시간'] = temp['시작 시간'].str.replace(':', '')
    temp['시작 시간'] = temp['시작 시간'].astype('int64')
    temp['시작 시간'] = temp['시작 시간'] * 100

    temp['종료시간'] = temp['종료시간'].str.replace(':', '')
    temp['종료시간'] = temp['종료시간'].astype('int64')
    temp['종료시간'] = (temp['종료시간'] * 100) + 59

    start = list(temp['시작 시간'])
    stop = list(temp['종료시간'])

    for i in range(len(start)):
        n.append(danigoIotDatas[date][(danigoIotDatas[date]['등록시간'] <= stop[i]) & (danigoIotDatas[date]['등록시간'] >= start[i])])
        m.append(outSideTemps[date][(outSideTemps[date]['시간'] <= stop[i]) & (outSideTemps[date]['시간'] >= start[i])])

    dataNow += 1

for i in range(len(n)):
    tempAvg.append(sum(n[i]['온도(°C)'])/len(n[i]['온도(°C)']))
    outTempAvg.append(sum(m[i]['기온(°C)'])/len(m[i]['기온(°C)']))

danigoApp['In_Temp'] = tempAvg
danigoApp['Out_Temp'] = outTempAvg

danigoApp = danigoApp[danigoApp['연료 사용량 (km)'] != 0]

distances = [4.2, 5.8, 6.6]
newdatasForTest = danigoApp[danigoApp['거리'] == distances[2]]

X = newdatasForTest["Out_Temp"]
y = newdatasForTest["연료 사용량 (km)"]

#newdatasForTest.to_excel('DistancesixOnly.xlsx', index=False)
#danigoApp.to_excel('AddTempertureD.xlsx', index=False)

outX = danigoApp["Out_Temp"]
outy = danigoApp["연료 사용량 (km)"]

line_fitter = LinearRegression()
line_fitter.fit(outX.values.reshape(-1,1), outy)

print('기울기: ', line_fitter.coef_)
print('절편: ', line_fitter.intercept_)

plt.plot(X, y, 'o')
plt.plot(X,line_fitter.predict(X.values.reshape(-1,1)))
plt.show()

inX = danigoApp["In_Temp"]
iny = danigoApp["연료 사용량 (km)"]

line_fitter = LinearRegression()
line_fitter.fit(inX.values.reshape(-1,1), iny)

print('기울기: ', line_fitter.coef_)
print('절편: ', line_fitter.intercept_)

plt.plot(inX, iny, 'o')
plt.plot(inX,line_fitter.predict(inX.values.reshape(-1,1)))
plt.show()

#다중회귀 모델을 짜보자
import numpy as np
import pandas as pd
import tensorflow as tf
from matplotlib import pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

from sklearn.linear_model import Lasso

Appdata=pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/APP/다니고밴.csv")

def outlier_remove(data, threshold=2.1):
    z_scores = np.abs(data - np.mean(data)) / np.std(data) # Z-score 계산

    filtered_data = data[z_scores < threshold]
    outlier = data[z_scores>threshold]

    return filtered_data, outlier

Appdata=pd.merge(Appdata,danigoApp)

#X 이상값 추출
filtered_time,outlier_t=outlier_remove(Appdata['소요 시간(분)'])
filtered_tl,outlier_tl=outlier_remove(Appdata['신호등 정지'])
filtered_intemp,outlier_in=outlier_remove(Appdata['In_Temp'])
filtered_outtemp,outlier_out=outlier_remove(Appdata['Out_Temp'])
filtered_dist,outlier_dist=outlier_remove(Appdata['거리'])

#Y 이상값 추출
filtered_fuel,outlier_f=outlier_remove(Appdata['연료 사용량 (km)'])

#X 이상값 제거
for i in outlier_t:
  Appdata.drop(Appdata[Appdata['소요 시간(분)'] == i].index)
for i in outlier_tl:
  Appdata.drop(Appdata[Appdata['신호등 정지'] == i].index)
for i in outlier_in:
  Appdata.drop(Appdata[Appdata['In_Temp'] == i].index)
for i in outlier_out:
  Appdata.drop(Appdata[Appdata['Out_Temp'] == i].index)
for i in outlier_dist:
  Appdata.drop(Appdata[Appdata['거리'] == i].index)
#Y 이상값 제거
for i in outlier_f:
  Appdata=Appdata[Appdata['연료 사용량 (km)'] != i]

#값 제거 안하면 0.13441536283220157 [-0.09425034 -0.06246091  0.00426062  0.116113   -0.01573865]

#값 제거 하면 0.12278575303028283 [-0.08173695 -0.04908362 -0.00548274  0.12570456 -0.01296417]
Appdata_X=Appdata[['거리','In_Temp','Out_Temp','신호등 정지','소요 시간(분)']]
Appdata_Y=Appdata['연료 사용량 (km)']

x_train, x_test, y_train, y_test = train_test_split(Appdata_X, Appdata_Y, train_size=0.8, test_size=0.2)

w1 = tf.Variable(tf.random.uniform([1]))
w2 = tf.Variable(tf.random.uniform([1]))
w3 = tf.Variable(tf.random.uniform([1]))
w4 = tf.Variable(tf.random.uniform([1]))
w5 = tf.Variable(tf.random.uniform([1]))
b = tf.Variable(tf.random.uniform([1]))

def loss_function():
# w*x는 행렬 곱셈 후, bias를 더하여 pred_y를 계산
  pred_y = w1*Appdata[['In_Temp']].values.tolist()+w2*Appdata[['Out_Temp']].values.tolist()+w3*Appdata[['거리']].values.tolist()+w4*Appdata[['소요 시간(분)']].values.tolist()+b
    #평균 제곱근 오차(Mean squared error)를 손실함수(loss function)으로 활용
  cost = tf.reduce_mean(tf.square(pred_y - Appdata_Y.values.tolist()))
  return cost


#보편적으로 가장 많이 사용하는 adam optimizer 활용
optimizer = tf.optimizers.Adam(learning_rate=0.01)
#훈련시키기
for step in range(3000):
    cost_val=optimizer.minimize(loss_function, var_list=[w1,w2,w3,b])
    if step % 100 == 0:
#훈련값 출력
        print(step,"loss_value:", loss_function().numpy(), 'weight:', w1.numpy(),w2.numpy(),w3.numpy(),w4.numpy(),w5.numpy(), 'bias:', b.numpy()[0])

pred_y_list= w1*Appdata[['In_Temp']].values.tolist()+w2*Appdata[['Out_Temp']].values.tolist()+w3*Appdata[['거리']].values.tolist()+w4*Appdata[['소요 시간(분)']].values.tolist()+w5*Appdata[['신호등 정지']] +b
print(pred_y_list) #실제 y값과 비교

# 실제 데이터 시각화
plt.title("Orginal data")
plt.xlabel("data number")
plt.ylabel("Label Y value")
plt.plot(Appdata_X, Appdata_Y, 'ro', label='Original data')
plt.show()

# 예측 데이터 시각화
plt.title("Predicted value")
plt.xlabel("data number")
plt.ylabel("Predicted Y value")
plt.plot(Appdata_Y, pred_y_list,'bo', label='Predicted data')
plt.legend()
plt.show()
"""
#General한 예측
model=LinearRegression()
model.fit(Appdata_X,Appdata_Y)
y_predict = model.predict(x_test)
print(model.score(Appdata_X,Appdata_Y))
print(model.coef_)
plt.scatter(y_test, y_predict.astype(int), alpha=0.4)
plt.xlabel("real Fuel")
plt.ylabel("predict_fuel_demand")
plt.title("MULTIPLE LINEAR REGRESSION")
plt.show() """

"""이 파트는 선형회귀 방식으로 푸는 방식이다 우선 시간 먼저 해보자

"""

import numpy as np
import pandas as pd

from matplotlib import pyplot as plt
from sklearn.linear_model import LinearRegression

#우선 파일을 읽는다.
Iot1=pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230309.csv")
iot2=pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230310.csv")
iot3=pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230311.csv")
iot4=pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230312.csv")
iot5=pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/LTE Device/다니고밴-[전주]Type12-역방향-20230313.csv")
Appdata=pd.read_csv("/content/gdrive/MyDrive/도로노선정보-20231114/다니고밴-[전주]Type12-역방향/APP/다니고밴-[전주]Type12-역방향-20231117.csv")
#필터링 함수
def outlier_remove(data, threshold=3):
    z_scores = np.abs(data - np.mean(data)) / np.std(data) # Z-score 계산

    filtered_data = data[z_scores < threshold]
    outlier = data[z_scores>threshold]

    return filtered_data, outlier

# 시간 ....필터링 해야됨...
X=np.array(Appdata['소요 시간(분)'].to_numpy())
filtered_X,outlierX=outlier_remove(X)
Y=np.array(Appdata['연료 사용량 (km)'].to_numpy())
filtered_Y,outlierY=outlier_remove(Y)

print(X)
print(Y)

# 데이터프레임에서 outlier 값을 뺴기 위해 실행
print(filtered_X)#필터된 값 확인
print(outlierX)#걸러진 값 확인
print(filtered_Y)
print(outlierY)

#이상값있는 데이터 시각화
timeline_fitter=LinearRegression() #선형회귀 함수 호출
timeline_fitter.fit(X.reshape(-1,1),Y.reshape(-1,1)) #예측
timeline_fitter.predict([[60]]) #example 60분을 달렸을 때 어느 정도의 값을 요구할 것인가
plt.plot(X, Y.reshape(-1,1), 'o') # 이하 시각화
plt.plot(X.reshape(-1,1),timeline_fitter.predict(X.reshape(-1,1)))
plt.show()

#이때 Threshold가 <=2가 되면 안되는데 그 이유는...뭐지...?

#Appdata.drop(Appdata[Appdata['소요 시간(분)']!=outlierX[i]])
#Appdata.drop(Appdata[Appdata['연료 사용량 (km)']!=outlierY[i]])

for i in outlierX:
  Appdata.drop(Appdata[Appdata['소요 시간(분)']!=outlierX[i]])

for i in outlierY:
  Appdata=(Appdata[Appdata['연료 사용량 (km)']!=outlierY[i]])

# 데이터 프레임에서 Filtered 값을 쓰기 위해 실행
X=np.array(Appdata['소요 시간(분)'].to_numpy())
filtered_X,outlierX=outlier_remove(X)
Y=np.array(Appdata['연료 사용량 (km)'].to_numpy())
filtered_Y,outlierY=outlier_remove(Y)

#이상값 없는 데이터 시각화
timeline_fitter=LinearRegression() #선형회귀 함수 호출
timeline_fitter.fit(filtered_X.reshape(-1,1),filtered_Y.reshape(-1,1)) #예측
print(timeline_fitter.predict([[60]])) #example 60분을 달렸을 때 어느 정도의 값을 요구할 것인가
plt.plot(filtered_X, filtered_Y.reshape(-1,1), 'o') # 이하 시각화
plt.plot(filtered_X.reshape(-1,1),timeline_fitter.predict(filtered_X.reshape(-1,1)))
plt.show()

#이 이하는 소요시간+휴게시간
X=np.array(Appdata['소요 시간(분)'].to_numpy())
filtered_X,outlierX=outlier_remove(X)
Y=np.array(Appdata['연료 사용량 (km)'].to_numpy())
filtered_Y,outlierY=outlier_remove(Y)
Z=np.array(Appdata['휴게 시간(분)'].to_numpy())
filtered_Z,outlierZ=outlier_remove(Z)

#이상값 없는 데이터 시각화
timeline_fitter=LinearRegression() #선형회귀 함수 호출
timeline_fitter.fit((filtered_X+filtered_Z).reshape(-1,1),filtered_Y.reshape(-1,1)) #예측
print(timeline_fitter.predict([[60]])) #example 60분을 달렸을 때 어느 정도의 값을 요구할 것인가
plt.plot((filtered_X+filtered_Z), filtered_Y.reshape(-1,1), 'o') # 이하 시각화
plt.plot((filtered_X+filtered_Z).reshape(-1,1),timeline_fitter.predict((filtered_X+filtered_Z).reshape(-1,1)))
plt.show()

# CSV 파일에서 데이터 로드
data = pd.read_csv("/content/sample_data/다니고밴-[전주]Type12-역방향-20231117.csv",encoding='utf-8')  # 파일 경로에 맞게 수정

data.head()

# 필요한 변수 선택
features = ['소요 시간(분)']  # 사용할 변수 선택 (온도만 사용)
target_variable = '연료 사용량 (km)'  # 예측할 변수 선택

print(data.head())

# 필요한 변수 선택
features = ['소요 시간(분)']  # 사용할 변수 선택 (온도만 사용)
target_variable = '연료 사용량 (km)'  # 예측할 변수 선택

# 온도 및 배터리 소모량 데이터만 추출 => 새로운 데이터 프레임 만들기
data = data[features + [target_variable]]

# 결측치 처리 (만약 있으면)
data = data.dropna()  # 결측치 제거

# 입력 변수와 출력 변수 분리
X = data[features].values  # (입력변수)features에 있는 열 선택 후 .values를 이용하여 numpy배열로 변환
y = data[target_variable].values  # (출력변수)

# 데이터 정규화
scaler = MinMaxScaler()  # Min-Max 스케일러를 사용하여 데이터를 [0, 1] 범위로 정규화
X_scaled = scaler.fit_transform(X)  # 1차원 배열을 열벡터 형태로 변환하여 정규화

# 학습 및 테스트 데이터로 분할
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)  # 데이터를 학습용과 테스트용으로 나눔
#(test_size : 데이터를 테스트세트로 사용할 비율)



# 데이터를 LSTM 입력 형태로 변환(데이터 전처리)
X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))  # LSTM 입력 형태로 데이터 변환
#2차원인 X_train을 3차원배열로 바꿔줌
X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))